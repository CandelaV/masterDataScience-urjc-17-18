---
title: "Inteligencia y Analítica de Negocios"
subtitle: "Práctica final T2 (Parte I)"
author: "Candela Vidal"
output:
  html_document:
    toc: yes
    toc_depth: '5'
    df_print: paged
mainfont: Roboto Light
fontsize: 12pt
---

• Datos: Fichero https://www.kaggle.com/fivethirtyeight/the-ultimate-halloween-candy-powerranking/data (origen: http://walthickey.com/2017/10/18/whats-the-best-halloween-candy/ ).

• Tecnologías: Python y Jupyter notebook o R/RStudio y RMarkdown.

• Fecha de entrega: Domingo, 6 de mayo de 2018, a las 23:55.

• En esta primera práctica vamos a afianzar el uso de herramientas de evaluación de modelos y validación de resultados.

```{r}
library(purrr)
library(tidyr)
library(ggplot2)
library(boot)
```

## 1 CARGA DEL FICHERO

Cargar el fichero de datos "./data/candy-data.csv", definiendo para ello la información de tipos de datos necesaria para interpretar las columnas adecuadamente en el lenguaje de programación seleccionado.

```{r}
candy <- read.csv('./data/candy-data.csv', colClasses=c('character', rep('factor', 9),rep('numeric',3)),header = TRUE)
```

```{r}
summary(candy)
```

Variables factor:

```{r}
candy %>%
  keep(is.factor) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_bar()
```

Variables numéricas:

```{r}
candy[,-13] %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram()
```

Variable objetivo:

```{r}
ggplot(candy, aes(winpercent)) + geom_histogram()
```

## 2 MODELO y eavaluación del mismo

El modelo que debemos ajustar es una regresión mútiple, utilizando como variable de salida los valores de la columna winpercent y como variables explicativas (entrada) todas las demás columnas. El objetivo del análisis es identificar qué factores están más relacionados con la elección de un tipo de caramelo como ganador sobre los restantes.

Se pueden obtener ideas adicionales sobre cómo se han utilizado los datos para un análisis real en este post *http://fivethirtyeight.com/features/the-ultimate-halloween-candy-power-ranking/* sobre el mismo dataset.

### Apartado A : Regresión Múltiple

Primero divide la muestra total de datos en un 75% para training y un 25% para testing. Ajusta un modelo de regresión múltiple sobre los datos de training y luego comprueba su efectividad para predecir los valores de los datos de testing. (3 puntos).

```{r}
set.seed(1)
train.size = 0.75
train.index = sample.int(length(candy$competitorname), round(length(candy$competitorname)*train.size))
train.sample = candy[train.index,]
test.sample = candy[-train.index,]
```

Definimos el modelo de regresión sobre los datos de training e incluyendo todas las variables excepto el nombre del caramelo:

```{r}
glm.fit = glm( winpercent ~ chocolate + fruity + caramel + peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent , data = train.sample)

summary(glm.fit)
```

El MSE (error cuadrático medio) o error que comete el modelo respecto a
los datos para la muestra de entrenamiento es:

```{r}
mean((train.sample$winpercent - predict(glm.fit, train.sample))^2)
```

Los valores predichos con el modelo sobre el conjunto de test frente a los valores reales son:

```{r}
data.frame(valor.predicho = predict(glm.fit, test.sample), valor.real = test.sample$winpercent)
```

El MSE para los datos de test es:

```{r}
mean((test.sample$winpercent - predict(glm.fit, test.sample))^2)
```

Intervalos de confianza al 95% para los estimadores de los datos de train:

```{r}
confint(glm.fit)
```

Observamos que para las variables "chocolate", "fruity", "peanutyalmondy" y "hard" se puede afirmar con un 95% de confianza que el valor de los estimadores se encuentra los suficientemente lejos de 0 como para resultar variables significativas en el modelo. 

### Apartado B : Bootstrap

Utilizando bootstrap, calcula nuevos intervalos de confianza (95%) para los estimadores de todos los regresores del modelo. ¿Son consistentes todos los valores obtenidos con los resultados del apartado anterior?. ¿Qué variables seleccionaría para mantenerlas en el modelo? (3 puntos).

La función con la que se calcularán los intevalos de confianza en el bootstrap es la siguiente: 

```{r}
set.seed(1)

boot.fn = function(data, index) return(confint(glm( winpercent ~ chocolate + fruity + caramel + peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent , data = data, subset = index)))
```


Producimos 100 estimaciones bootstrap para los intervalos de confianza de cada uno de los estimadores del modelo sobre el conjunto completo de datos "candy".

```{r, include=FALSE, }
boot.candy = boot(candy, boot.fn, 100)
```

```{r}
boot.candy$t0
```

De los resultados obtenidos se puede deducir que al igual que en el apartado A, las variables más significativas en el modelo son "chocolate", "fruity", "peanutyalmondy" y "hard", pues son aquellas para las que con un 95% de confianza se puede decir que el valor del estimador se encuentra lo sificientemente alejado de 0.


### Apartado C : k-fold validation

Ahora realiza una validación cruzada (k-fold validation) con K=5. Compara la nueva estimación del MSE con la obtenida inicialmente ¿Qué podemos concluir acerca de la robustez del modelo?. (4 puntos).

A continuación creamos un nuevo modelo utilizando todos los valores de la muestra por ser esta pequeña y seleccionando unicamente las variables que interesan ("chocolate", "fruity", "peanutyalmondy" y "hard"). Con ello calculamos una nueva estimación del MSE utilizando la función cv.glm y K=5.

```{r}
set.seed (1)
glm.cv.fit=glm(winpercent ~ chocolate + fruity + peanutyalmondy + hard, data=candy)
cv.error.5 = cv.glm(candy,glm.cv.fit,K=5)$delta
cv.error.5
```

Obtenemos un vector con dos componentes. La primera es el error en crudo del MSE utilizando cross validation, mientras que la segunda tiene en cuenta el sesgo instroducido por no utilizar "leave-one-out" cross validation.

Observamos como el MSE ($133.02$) es ligeramente inferior al calculado en el apartado A para el modelo original con los datos de test ($141.28$). Esto nos induce a pensar que se trata de un modelo bastante robusto.
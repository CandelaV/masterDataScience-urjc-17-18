{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparacion librerias spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load external packages programatically\n",
    "# llamamos a MAVEN organiz:artefacto:version(scala)\n",
    "#                 com.databricks:spark-xml_2.11:0.4.1\n",
    "import os\n",
    "packages = \"com.databricks:spark-xml_2.11:0.4.1\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\"--packages {0} pyspark-shell\".format(packages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iniciamos sesion con pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.cores\", 1)\n",
    "    .appName(\"xml2json_dblp\")\n",
    "    .getOrCreate() )\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit,col,udf,explode\n",
    "from pyspark.sql.types import StringType,StructType,StructField,ArrayType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leemos el xml para cada tipo de publicación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schemaDBLP = StructType([\\\n",
    "    StructField(\"_key\", StringType(), True), \\\n",
    "    StructField(\"author\", ArrayType(StructType([StructField(\"_VALUE\", StringType())]))),\\\n",
    "    StructField(\"title\", StructType([StructField(\"_VALUE\", StringType())])),\\\n",
    "    StructField(\"year\", IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_incollection = (spark.read.format('xml')\n",
    "                 .options(rowTag='incollection', rootTag='incollection')                 \n",
    "                 .load('dblp.xml', schema = schemaDBLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_inproceedings = (spark.read.format('xml')\n",
    "                 .options(rowTag='inproceedings', rootTag='inproceedings')                 \n",
    "                 .load('dblp.xml', schema = schemaDBLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_article = (spark.read.format('xml')\n",
    "                 .options(rowTag='article', rootTag='article')                 \n",
    "                 .load('dblp.xml', schema = schemaDBLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminamos registros vacíos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_incollection = df_incollection.na.drop(subset=[\"_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_inproceedings = df_inproceedings.na.drop(subset=[\"_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_article = df_article.na.drop(subset=[\"_key\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadimos columna con el tipo de publicación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incollection = df_incollection.withColumn('type', lit('incollection'))\n",
    "df_incollection.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inproceedings = df_inproceedings.withColumn('type', lit('inproceedings'))\n",
    "df_inproceedings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article = df_article.withColumn('type', lit('article'))\n",
    "df_article.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambiamos \"title\" de struct a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_incollection = df_incollection.select('_key','author','title._VALUE','year','type')\n",
    "df_incollection = df_incollection.withColumnRenamed('_VALUE', 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_inproceedings = df_inproceedings.select('_key','author','title._VALUE','year','type')\n",
    "df_inproceedings = df_inproceedings.withColumnRenamed('_VALUE', 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_article = df_article.select('_key','author','title._VALUE','year','type')\n",
    "df_article = df_article.withColumnRenamed('_VALUE', 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminamos la etiqueta \"_VALUE\" del campo \"author\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tuples2list(lista):\n",
    "    if lista is not None:\n",
    "        lista_final = []\n",
    "        for value in lista:\n",
    "            lista_final.append(value[0])\n",
    "        return lista_final\n",
    "tuples2list_udf = udf(tuples2list, ArrayType(StringType(),False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incollection = df_incollection.withColumn(\"author\", tuples2list_udf(df_incollection.author))\n",
    "df_incollection.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incollection.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inproceedings = df_inproceedings.withColumn(\"author\", tuples2list_udf(df_inproceedings.author))\n",
    "df_inproceedings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inproceedings.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article = df_article.withColumn(\"author\", tuples2list_udf(df_article.author))\n",
    "df_article.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabamos en .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_incollection.coalesce(1).write.format('json').save('json_incollection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_inproceedings.coalesce(1).write.format('json').save('json_inproceedings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_article.coalesce(1).write.format('json').save('json_article')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unimos los tres dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_union = df_incollection.union(df_inproceedings).union(df_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_union.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_union.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASO 1. Grabamos csv para carga en neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list2neo4jstr(lista):\n",
    "    if lista is not None:\n",
    "        return str(lista).replace(\",\",\";\").lstrip(\"[\").rstrip(\"]\")\n",
    "\n",
    "list2neo4jstr_udf = udf(list2neo4jstr, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_union.withColumn(\"author\", list2neo4jstr_udf(df.author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.coalesce(1).write.option(\"header\", \"true\").csv(\"neo4j_input.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASO 2. Grabajos 3 csv para importar en neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_colecciones = df_union.select(\"_key\",\"year\")\n",
    "df_colecciones = df_colecciones.withColumnRenamed(\"_key\", \"collectionId:ID(Collection)\")\n",
    "df_colecciones = df_colecciones.withColumnRenamed(\"yar\",\"year:INT\")\n",
    "df_colecciones.printSchema()\n",
    "df_colecciones.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relaciones = df_union.select(col(\"_key\"),explode(col(\"author\")).alias(\"author\"))\n",
    "df_relaciones = df_relaciones.withColumnRenamed(\"_key\", \":START_ID(Collection)\")\n",
    "df_relaciones = df_relaciones.withColumnRenamed(\"author\",\":END_ID(Author)\")\n",
    "df_relaciones.printSchema()\n",
    "df_relaciones.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_autores = df_relaciones.select(\":END_ID(Author)\").distinct()\n",
    "df_autores = df_autores.withColumnRenamed(\":END_ID(Author)\", \"authorId:ID(Author)\")\n",
    "df_autores.printSchema()\n",
    "df_autores.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_colecciones.coalesce(1).write.option(\"header\", \"true\").csv(\"colecciones.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_relaciones.coalesce(1).write.option(\"header\", \"true\").csv(\"relaciones.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_autores.coalesce(1).write.option(\"header\", \"true\").csv(\"autores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANEXO 1. Consultas con Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df_union.withColumn(\"author_separado\", explode(df.author))\n",
    "df3 = df2.select('_key','author_separado','title','year','type')\n",
    "df3.registerTempTable('publicaciones')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listado de todas las publicaciones de un autor determinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = spark.sql(\"\"\"\n",
    "SELECT author_separado as author,\n",
    "       title           as titulo       \n",
    "       FROM publicaciones \n",
    "WHERE author_separado ='Javier M. Moguerza'\n",
    "\"\"\")\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de publicaciones de un autor determinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = spark.sql(\"\"\"\n",
    "SELECT author_separado as author,\n",
    "       count(*)        as num_publicaciones \n",
    "       FROM publicaciones \n",
    "WHERE author_separado ='Javier M. Moguerza'\n",
    "GROUP BY author_separado\n",
    "\"\"\")\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numero de articulos en revista para el año 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = spark.sql(\"\"\" SELECT count(*) as Num_articles\n",
    "                  FROM authorjuntos \n",
    "                  WHERE year='2017' AND type='article'\n",
    "               \"\"\")\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numero de autores ocasionales, es decir, que tengan menos de 5 publicaciones en total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = spark.sql(\"\"\" SELECT count(*) as num_autores_ocasionales\n",
    "                  FROM (SELECT  author_separado as author\n",
    "                              , count(*)        as num_publicaciones\n",
    "                          FROM publicaciones\n",
    "                          GROUP BY author_separado\n",
    "                          ORDER BY 2 asc\n",
    "                         )\n",
    "                  WHERE num_publicaciones < 5  \n",
    "               \"\"\")\n",
    "e.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edad de los 5 autores con un periodo de publicacion más largo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = spark.sql(\"\"\" SELECT author,\n",
    "                        maxyear - minyear as edad_autor\n",
    "                  FROM(  \n",
    "                        SELECT   author_separado as author\n",
    "                                ,max(year) as maxyear \n",
    "                                ,min(year) as minyear \n",
    "                        FROM publicaciones                         \n",
    "                        GROUP BY author_separado\n",
    "                        ORDER BY 1,2,3\n",
    "                       ) \n",
    "                  ORDER BY 2 desc\n",
    "                  LIMIT 5\n",
    "               \"\"\")\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de autores novatos, e.d que tengan una edad menor 5 años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = spark.sql(\"\"\" SELECT count(*) as Num_autores_novatos\n",
    "                  FROM(\n",
    "                          SELECT author,\n",
    "                                 maxyear - minyear as edad_autor\n",
    "                          FROM(  \n",
    "                                 SELECT   author_separado as author\n",
    "                                         ,max(year) as maxyear \n",
    "                                         ,min(year) as minyear \n",
    "                                 FROM publicaciones                                  \n",
    "                                 GROUP BY author_separado\n",
    "                                 ORDER BY 1,2,3\n",
    "                               ) \n",
    "                          ORDER BY 2 desc\n",
    "                       )   \n",
    "                 WHERE edad_autor < 5\n",
    "               \"\"\")\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramos el contexto de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
